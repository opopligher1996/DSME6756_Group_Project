{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7995e093-12cd-474a-8f6c-7d2ac971534b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98256f8-a880-4ba6-b26e-dd03cbc0bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_hursat(years):\n",
    "    best_track_data = pd.read_csv('/Users/opopligher1996/workspace/master/BusinessIntelligenceTechniquesAndApplications_DSME6756/project/DSME6756_Group_Project/Section_2/cyclone_intensity/dataset/besttrack.csv')\n",
    "\n",
    "    for year in years:\n",
    "        year_directory_url = 'https://www.ncei.noaa.gov/data/hurricane-satellite-hursat-b1/archive/v06/' + year\n",
    "        year_directory_page = requests.get(year_directory_url).text\n",
    "        year_directory_soup = BeautifulSoup(year_directory_page, 'html.parser')\n",
    "        year_directory_file_urls = [year_directory_url + '/' + node.get('href') for node in\n",
    "                                    year_directory_soup.find_all('a') if node.get('href').endswith('tar.gz')]\n",
    "        print('\\n' + year + ' file loaded.')\n",
    "\n",
    "        files_processed = 0\n",
    "        for storm_file_url in year_directory_file_urls:\n",
    "            print(storm_file_url)\n",
    "            # Determine whether the best track dataset has information about this particular hurricane. This filters\n",
    "            # out storms in basins other than the Atlantic or Pacific, since the best track dataset doesn't have\n",
    "            # information for those storms.\n",
    "            storm_name = storm_file_url.split('_')[-2]\n",
    "            year = int(storm_file_url.split('_')[3][:4])\n",
    "            file_has_match_in_best_track = not best_track_data.loc[\n",
    "                (best_track_data['year'] == year) & (best_track_data['storm_name'] == storm_name)\n",
    "            ].empty\n",
    "\n",
    "            if file_has_match_in_best_track:\n",
    "                # Build a string, which will be file path where we save the .tar.gz when downloaded\n",
    "                file_name = storm_file_url.split('/')[-1]\n",
    "                storm_file_path = 'Satellite Imagery/' + file_name\n",
    "\n",
    "                # Create the Satellite Imagery folder if it doesn't already exist\n",
    "                if not os.path.exists('Satellite Imagery'):\n",
    "                    os.makedirs('Satellite Imagery')\n",
    "\n",
    "                # Open the .tar.gz and copy it's contents from the web, onto our computer\n",
    "                request = requests.get(storm_file_url, allow_redirects=True)\n",
    "                open(storm_file_path, 'wb').write(request.content)\n",
    "                request.close()\n",
    "\n",
    "                # Open the .tar.gz file and loop through each file inside. Each of these netcdf files contains a\n",
    "                # satellite image of a hurricane at a moment in time\n",
    "                tar = tarfile.open(storm_file_path)\n",
    "                file_prefixes_in_directory = []\n",
    "                for file_name in tar.getnames():\n",
    "                    # Get the date and time of the satellite image, and the name of the satellite that took the image\n",
    "                    fulldate = file_name.split(\".\")[2] + file_name.split(\".\")[3] + file_name.split(\".\")[4]\n",
    "                    time = file_name.split(\".\")[5]\n",
    "                    satellite = file_name.split(\".\")[7][:3]\n",
    "\n",
    "                    # Determine whether the best track dataset has a record for the date and time of this storm.\n",
    "                    file_has_match_in_best_track = not best_track_data.loc[\n",
    "                        (best_track_data['fulldate'] == int(fulldate)) & (best_track_data['time'] == int(time))].empty\n",
    "\n",
    "                    # Determine whether another image of this hurricane at this exact time has already been extracted\n",
    "                    # from the .tar.gz\n",
    "                    is_redundant = '.'.join(file_name.split('.')[:6]) in file_prefixes_in_directory\n",
    "\n",
    "                    # If the requirements are met, extract the netcdf file from this .tar.gz and save it locally\n",
    "                    if file_has_match_in_best_track and not is_redundant and satellite == \"GOE\":\n",
    "                        f = tar.extractfile(file_name)\n",
    "                        open('Satellite Imagery/' + file_name, 'wb').write(f.read())\n",
    "                        file_prefixes_in_directory.append('.'.join(file_name.split('.')[:6]))\n",
    "\n",
    "                tar.close()\n",
    "                os.remove(storm_file_path)\n",
    "\n",
    "            files_processed += 1\n",
    "            print_progress('Processing Files for ' + str(year), files_processed, len(year_directory_file_urls))\n",
    "\n",
    "\n",
    "def print_progress(action, progress, total):\n",
    "    percent_progress = round((progress / total) * 100, 1)\n",
    "    print('\\r' + action + '... ' + str(percent_progress) + '% (' + str(progress) + ' of ' + str(total) + ')', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a06bf-1d0e-4673-afbb-f9d5298f49e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # YEARS_TO_DOWNLOAD = ['2016', '2015', '2014', '2013', '2012']\n",
    "    YEARS_TO_DOWNLOAD = ['2016']\n",
    "\n",
    "    download_hursat(YEARS_TO_DOWNLOAD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
